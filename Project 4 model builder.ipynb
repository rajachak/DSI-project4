{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "weather = pd.read_csv('weather.csv')\n",
    "spray = pd.read_csv('spray.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge data (only using station 1 so as not to double the data)\n",
    "trw = train.merge(weather[weather['Station']==1], how='left', on='Date')\n",
    "tsw = test.merge(weather[weather['Station']==1], how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Date', 'Address', 'Species', 'Block', 'Street', 'Trap',\n",
       "       'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy',\n",
       "       'Station', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb',\n",
       "       'Heat', 'Cool', 'Sunrise', 'Sunset', 'CodeSum', 'Depth', 'Water1',\n",
       "       'SnowFall', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed',\n",
       "       'ResultDir', 'AvgSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create y\n",
    "ytr = trw.WnvPresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create X\n",
    "Xtr = pd.DataFrame()\n",
    "Xts = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#FEATURE ENGINEERING\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean data, eliminate nulls\n",
    "#create dummies \n",
    "#engineer data data (day of year?, sunrise?)\n",
    "#engineer geographic variables\n",
    "#engineer weather variables (lagging data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummy variables for mosquito species that have Wnv\n",
    "tsw_species = pd.get_dummies(tsw['Species'])[['CULEX PIPIENS/RESTUANS','CULEX PIPIENS','CULEX RESTUANS']]\n",
    "trw_species = pd.get_dummies(trw['Species'])[['CULEX PIPIENS/RESTUANS','CULEX PIPIENS','CULEX RESTUANS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trw[trw.WnvPresent==1].Species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build X \n",
    "Xtr['Latitude'] = trw.Latitude\n",
    "Xts['Latitude'] = tsw.Latitude\n",
    "#\n",
    "Xtr['Longitude'] = trw.Longitude\n",
    "Xts['Longitude'] = tsw.Longitude\n",
    "#\n",
    "Xtr['Tmax'] = trw.Tmax.astype(float)\n",
    "Xts['Tmax'] = tsw.Tmax.astype(float)\n",
    "#\n",
    "Xtr['CULEX PIPIENS/RESTUANS'] = trw_species['CULEX PIPIENS/RESTUANS']\n",
    "Xts['CULEX PIPIENS/RESTUANS'] = tsw_species['CULEX PIPIENS/RESTUANS']\n",
    "Xtr['CULEX PIPIENS'] = trw_species['CULEX PIPIENS']\n",
    "Xts['CULEX PIPIENS'] = tsw_species['CULEX PIPIENS']\n",
    "Xtr['CULEX RESTUANS'] = trw_species['CULEX RESTUANS']\n",
    "Xts['CULEX RESTUANS'] = tsw_species['CULEX RESTUANS']\n",
    "#Xtr['PrecipTotal']= trw.PrecipTotal.apply(lambda x: 0.1 if x == 'T' else x)\n",
    "#Xts['PrecipTotal']= tsw.PrecipTotal.apply(lambda x: 0.1 if x == 'T' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check dtypes\n",
    "#Xtr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for nulls\n",
    "#Xtr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xts.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "#BUILD MODELS\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92822186, 0.93553652, 0.92900857])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######RANDOM FOREST model\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtr, ytr, test_size=0.30, random_state=12)\n",
    "#run random forest with kfold (may not be necessary, but will give an estimate of variance)\n",
    "model = RandomForestClassifier(max_features = 3, max_depth = 1000) \n",
    "scores = cross_val_score(model, X_train, y_train, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9589758233390444"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit against full training set\n",
    "model.fit(Xtr,ytr)\n",
    "model.score(Xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#KERAS MODEL\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create keras Model\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtr, ytr, test_size=0.30, random_state=11)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)  #the scaler is fit only to the training data\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_units = X_train.shape[1] #number of features in training set\n",
    "hidden_units = input_units   #hidden layer has the same number of nodes as input\n",
    "\n",
    "#first input layer\n",
    "model.add(Dense(hidden_units            \n",
    "                ,input_dim=input_units  \n",
    "                ,activation='relu'\n",
    "                #uncomment this to add L2 regularization\n",
    "                #,kernel_regularizer=regularizers.l2(0.0001) \n",
    "               ))\n",
    "\n",
    "\n",
    "#hidden layer (try with and without)\n",
    "#node_reduction = 0\n",
    "#model.add(Dense(hidden_units - node_reduction          \n",
    "#                ,input_dim=input_units  \n",
    "#                ,activation='relu'\n",
    "#                #,kernel_regularizer=regularizers.l2(0.0001) \n",
    "#               ))\n",
    "#model.add(Dropout(0.8))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy'\n",
    "              ,optimizer='adam'\n",
    "               #added later (not part of original solution\n",
    "              ,metrics=['binary_accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7354 samples, validate on 3152 samples\n",
      "Epoch 1/20\n",
      "7354/7354 [==============================] - 1s 123us/step - loss: 0.5384 - binary_accuracy: 0.8247 - val_loss: 0.3804 - val_binary_accuracy: 0.9489\n",
      "Epoch 2/20\n",
      "7354/7354 [==============================] - 0s 49us/step - loss: 0.2974 - binary_accuracy: 0.9470 - val_loss: 0.2324 - val_binary_accuracy: 0.9489\n",
      "Epoch 3/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.2203 - binary_accuracy: 0.9470 - val_loss: 0.2046 - val_binary_accuracy: 0.9489\n",
      "Epoch 4/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.2061 - binary_accuracy: 0.9470 - val_loss: 0.1996 - val_binary_accuracy: 0.9489\n",
      "Epoch 5/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.2024 - binary_accuracy: 0.9470 - val_loss: 0.1981 - val_binary_accuracy: 0.9489\n",
      "Epoch 6/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.2005 - binary_accuracy: 0.9470 - val_loss: 0.1975 - val_binary_accuracy: 0.9489\n",
      "Epoch 7/20\n",
      "7354/7354 [==============================] - 0s 45us/step - loss: 0.1996 - binary_accuracy: 0.9470 - val_loss: 0.1969 - val_binary_accuracy: 0.9489\n",
      "Epoch 8/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.1987 - binary_accuracy: 0.9470 - val_loss: 0.1965 - val_binary_accuracy: 0.9489\n",
      "Epoch 9/20\n",
      "7354/7354 [==============================] - 0s 51us/step - loss: 0.1980 - binary_accuracy: 0.9470 - val_loss: 0.1961 - val_binary_accuracy: 0.9489\n",
      "Epoch 10/20\n",
      "7354/7354 [==============================] - 0s 49us/step - loss: 0.1974 - binary_accuracy: 0.9470 - val_loss: 0.1958 - val_binary_accuracy: 0.9489\n",
      "Epoch 11/20\n",
      "7354/7354 [==============================] - 0s 45us/step - loss: 0.1970 - binary_accuracy: 0.9470 - val_loss: 0.1954 - val_binary_accuracy: 0.9489\n",
      "Epoch 12/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.1967 - binary_accuracy: 0.9470 - val_loss: 0.1951 - val_binary_accuracy: 0.9489\n",
      "Epoch 13/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.1962 - binary_accuracy: 0.9470 - val_loss: 0.1950 - val_binary_accuracy: 0.9489\n",
      "Epoch 14/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.1960 - binary_accuracy: 0.9470 - val_loss: 0.1947 - val_binary_accuracy: 0.9489\n",
      "Epoch 15/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.1957 - binary_accuracy: 0.9470 - val_loss: 0.1944 - val_binary_accuracy: 0.9489\n",
      "Epoch 16/20\n",
      "7354/7354 [==============================] - 0s 47us/step - loss: 0.1954 - binary_accuracy: 0.9470 - val_loss: 0.1943 - val_binary_accuracy: 0.9489\n",
      "Epoch 17/20\n",
      "7354/7354 [==============================] - 0s 46us/step - loss: 0.1952 - binary_accuracy: 0.9470 - val_loss: 0.1941 - val_binary_accuracy: 0.9489\n",
      "Epoch 18/20\n",
      "7354/7354 [==============================] - 0s 51us/step - loss: 0.1950 - binary_accuracy: 0.9470 - val_loss: 0.1939 - val_binary_accuracy: 0.9489\n",
      "Epoch 19/20\n",
      "7354/7354 [==============================] - 0s 49us/step - loss: 0.1949 - binary_accuracy: 0.9470 - val_loss: 0.1937 - val_binary_accuracy: 0.9489\n",
      "Epoch 20/20\n",
      "7354/7354 [==============================] - 0s 50us/step - loss: 0.1947 - binary_accuracy: 0.9470 - val_loss: 0.1936 - val_binary_accuracy: 0.9489\n"
     ]
    }
   ],
   "source": [
    "#Run Keras model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "              epochs=20, batch_size=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add some visualization here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "#SCORE MODEL\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.670295565786386"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate AUC-ROC against the test portion of our train-test split\n",
    "y_preds = model.predict(X_test)\n",
    "metrics.roc_auc_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run model against the kaggle test dataset\n",
    "test_preds = model.predict(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsw.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate output file  (not working for neural network)\n",
    "\n",
    "output_file = pd.DataFrame({'Id':tsw.Id, 'WnvPresent':test_preds})\n",
    "#output_file.head()\n",
    "csv_name = 'test_csv.csv'\n",
    "output_file.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
