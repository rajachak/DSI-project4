{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10506, 33) (116293, 32)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "weather = pd.read_csv('weather.csv')\n",
    "spray = pd.read_csv('spray.csv')\n",
    "#merge data (only using station 1 so as not to double the data)\n",
    "trw = train.merge(weather[weather['Station']==1], how='left', on='Date')\n",
    "tsw = test.merge(weather[weather['Station']==1], how='left', on='Date')\n",
    "print(trw.shape, tsw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#since classes are unbalanced, oversample WnvPresent = 1\n",
    "#trw = trw.append(trw[trw.WnvPresent==1])   #didn't make any difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Date', 'Address', 'Species', 'Block', 'Street', 'Trap',\n",
       "       'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy',\n",
       "       'Station', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb',\n",
       "       'Heat', 'Cool', 'Sunrise', 'Sunset', 'CodeSum', 'Depth', 'Water1',\n",
       "       'SnowFall', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed',\n",
       "       'ResultDir', 'AvgSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10506, 33) (116293, 32)\n"
     ]
    }
   ],
   "source": [
    "print(trw.shape, tsw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551, 33)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate baseline\n",
    "trw[trw.WnvPresent == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#FEATURE ENGINEERING\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unsued features (random forest crossval score didn't improve):\n",
    "#\n",
    "# Xtr['Lat1'] = trw.Latitude.round(1)\n",
    "# Xts['Lat1'] = tsw.Latitude.round(1)\n",
    "\n",
    "# Xtr['Long1'] = trw.Longitude\n",
    "# Xts['Long1'] = tsw.Longitude\n",
    "\n",
    "# Xtr['DewPoint'] = trw.DewPoint\n",
    "# Xts['DewPoint'] = tsw.DewPoint\n",
    "\n",
    "# Xtr['StnPressure'] = trw['StnPressure']\n",
    "# ytr = ytr.drop(Xtr[Xtr['StnPressure']=='M'].index)\n",
    "# Xtr = Xtr.drop(Xtr[Xtr['StnPressure']=='M'].index)\n",
    "# Xtr['StnPressure'] = Xtr['StnPressure'].astype(float)\n",
    "# Xts['StnPressure'] = tsw['StnPressure'].astype(float)\n",
    "# #\n",
    "# Xtr['AvgSpeed'] = trw['AvgSpeed'].astype(float)\n",
    "# Xts['AvgSpeed'] = tsw['AvgSpeed'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need work\n",
    "#Xtr['PrecipTotal']= trw.PrecipTotal.apply(lambda x: 0.1 if x == 'T' else x)\n",
    "#Xts['PrecipTotal']= tsw.PrecipTotal.apply(lambda x: 0.1 if x == 'T' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean data, eliminate nulls\n",
    "#create dummies \n",
    "#engineer data data (day of year?, sunrise?)\n",
    "#engineer geographic variables\n",
    "#engineer weather variables (lagging data)\n",
    "#what to do about the 50 per trap limit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummy variables for only for mosquito species that have Wnv \n",
    "tsw_species = pd.get_dummies(tsw['Species'])[['CULEX PIPIENS/RESTUANS','CULEX PIPIENS','CULEX RESTUANS']]\n",
    "trw_species = pd.get_dummies(trw['Species'])[['CULEX PIPIENS/RESTUANS','CULEX PIPIENS','CULEX RESTUANS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10506,)\n",
      "(10506, 2) (10506,)\n",
      "(10413, 8) (10413,)\n",
      "(116293, 8)\n"
     ]
    }
   ],
   "source": [
    "ytr = trw.WnvPresent\n",
    "print(ytr.shape)\n",
    "#Build X \n",
    "Xtr = pd.DataFrame()\n",
    "Xts = pd.DataFrame()\n",
    "#\n",
    "Xtr['Latitude'] = trw.Latitude\n",
    "Xts['Latitude'] = tsw.Latitude\n",
    "Xtr['Longitude'] = trw.Longitude\n",
    "Xts['Longitude'] = tsw.Longitude\n",
    "#\n",
    "print(Xtr.shape, ytr.shape)\n",
    "Xtr['Tmax'] = trw.Tmax.astype(float)\n",
    "Xts['Tmax'] = tsw.Tmax.astype(float)\n",
    "#\n",
    "Xtr['CULEX PIPIENS/RESTUANS'] = trw_species['CULEX PIPIENS/RESTUANS']\n",
    "Xts['CULEX PIPIENS/RESTUANS'] = tsw_species['CULEX PIPIENS/RESTUANS']\n",
    "Xtr['CULEX PIPIENS'] = trw_species['CULEX PIPIENS']\n",
    "Xts['CULEX PIPIENS'] = tsw_species['CULEX PIPIENS']\n",
    "Xtr['CULEX RESTUANS'] = trw_species['CULEX RESTUANS']\n",
    "Xts['CULEX RESTUANS'] = tsw_species['CULEX RESTUANS']\n",
    "#\n",
    "Xtr['DayOfYear'] = pd.to_datetime(trw['Date'], format='%Y-%m-%d').dt.dayofyear\n",
    "Xts['DayOfYear'] = pd.to_datetime(tsw['Date'], format='%Y-%m-%d').dt.dayofyear\n",
    "#\n",
    "Xtr['WetBulb'] = trw.WetBulb\n",
    "ytr = ytr.drop(Xtr[Xtr['WetBulb']=='M'].index)\n",
    "Xtr = Xtr.drop(Xtr[Xtr['WetBulb']=='M'].index)\n",
    "Xtr['WetBulb'] = Xtr['WetBulb'].astype(float)\n",
    "Xts['WetBulb'] = tsw.WetBulb.astype(float)                   #didn't have any 'M values\n",
    "#\n",
    "\n",
    "print(Xtr.shape, ytr.shape)\n",
    "print(Xts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dtypes\n",
    "#print(Xtr.dtypes)\n",
    "#print(ytr.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for nulls\n",
    "#print(Xtr.isnull().sum())\n",
    "#print(Xts.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xts.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "#BUILD MODELS\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Sklearn models\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86117512 0.94670124 0.68674352]\n",
      "0.8315399566311958\n"
     ]
    }
   ],
   "source": [
    "####### ADABoost model\n",
    "model = AdaBoostClassifier(n_estimators=100) \n",
    "scores = cross_val_score(model, Xtr, ytr, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62327189 0.93546528 0.63544669]\n",
      "0.7313946196865916\n"
     ]
    }
   ],
   "source": [
    "#######RANDOM FOREST model\n",
    "#not necessary\n",
    "#X_train, X_test, y_train, y_test = train_test_split(Xtr, ytr, test_size=0.30, random_state=12)\n",
    "#run random forest with kfold (may not be necessary, but will give an estimate of variance)\n",
    "model = RandomForestClassifier(max_features = 6, max_depth = 20) \n",
    "scores = cross_val_score(model, Xtr, ytr, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58006912 0.94237972 0.44553314]\n",
      "0.6559939944316514\n"
     ]
    }
   ],
   "source": [
    "#######GRADIENT BOOSTING model\n",
    "#not necessary\n",
    "#X_train, X_test, y_train, y_test = train_test_split(Xtr, ytr, test_size=0.30, random_state=12)\n",
    "#run random forest with kfold (may not be necessary, but will give an estimate of variance)\n",
    "model = GradientBoostingClassifier(max_features = 6, max_depth = 100) \n",
    "scores = cross_val_score(model, Xtr, ytr, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9470853740516662"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit against full training set\n",
    "model.fit(Xtr,ytr)\n",
    "model.score(Xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521624737162313"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metrics.roc_auc_score(ytr,y_preds)\n",
    "y_preds = model.predict_proba(Xtr)[:,1]\n",
    "metrics.roc_auc_score(ytr,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#KERAS MODEL\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7289, 8) (7289,)\n",
      "(3124, 8) (3124,)\n"
     ]
    }
   ],
   "source": [
    "#Create keras Model\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtr, ytr, test_size=0.30, random_state=11)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)  #the scaler is fit only to the training data\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_units = X_train.shape[1] #number of features in training set\n",
    "hidden_units = input_units   #hidden layer has the same number of nodes as input\n",
    "\n",
    "#first input layer\n",
    "model.add(Dense(hidden_units            \n",
    "                ,input_dim=input_units  \n",
    "                ,activation='relu'\n",
    "                #uncomment this to add L2 regularization\n",
    "                #,kernel_regularizer=regularizers.l2(0.0001) \n",
    "               ))\n",
    "\n",
    "\n",
    "#hidden layer (try with and without)\n",
    "node_reduction = 0\n",
    "model.add(Dense(hidden_units - node_reduction          \n",
    "                ,input_dim=input_units  \n",
    "                ,activation='relu'\n",
    "                #,kernel_regularizer=regularizers.l2(0.0001) \n",
    "               ))\n",
    "#model.add(Dropout(0.8))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy'\n",
    "              ,optimizer='adam'\n",
    "               #added later (not part of original solution\n",
    "              ,metrics=['binary_accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7289 samples, validate on 3124 samples\n",
      "Epoch 1/20\n",
      "7289/7289 [==============================] - 1s 197us/step - loss: 0.7301 - binary_accuracy: 0.6238 - val_loss: 0.3361 - val_binary_accuracy: 0.9494\n",
      "Epoch 2/20\n",
      "7289/7289 [==============================] - 0s 55us/step - loss: 0.2650 - binary_accuracy: 0.9461 - val_loss: 0.2157 - val_binary_accuracy: 0.9494\n",
      "Epoch 3/20\n",
      "7289/7289 [==============================] - 0s 55us/step - loss: 0.2145 - binary_accuracy: 0.9461 - val_loss: 0.1972 - val_binary_accuracy: 0.9494\n",
      "Epoch 4/20\n",
      "7289/7289 [==============================] - 0s 55us/step - loss: 0.2049 - binary_accuracy: 0.9461 - val_loss: 0.1918 - val_binary_accuracy: 0.9494\n",
      "Epoch 5/20\n",
      "7289/7289 [==============================] - 0s 55us/step - loss: 0.2009 - binary_accuracy: 0.9461 - val_loss: 0.1888 - val_binary_accuracy: 0.9494\n",
      "Epoch 6/20\n",
      "7289/7289 [==============================] - 0s 54us/step - loss: 0.1987 - binary_accuracy: 0.9461 - val_loss: 0.1871 - val_binary_accuracy: 0.9494\n",
      "Epoch 7/20\n",
      "7289/7289 [==============================] - 0s 54us/step - loss: 0.1969 - binary_accuracy: 0.9461 - val_loss: 0.1855 - val_binary_accuracy: 0.9494\n",
      "Epoch 8/20\n",
      "7289/7289 [==============================] - 0s 54us/step - loss: 0.1957 - binary_accuracy: 0.9461 - val_loss: 0.1846 - val_binary_accuracy: 0.9494\n",
      "Epoch 9/20\n",
      "7289/7289 [==============================] - 0s 54us/step - loss: 0.1944 - binary_accuracy: 0.9461 - val_loss: 0.1833 - val_binary_accuracy: 0.9494\n",
      "Epoch 10/20\n",
      "7289/7289 [==============================] - 0s 60us/step - loss: 0.1933 - binary_accuracy: 0.9461 - val_loss: 0.1824 - val_binary_accuracy: 0.9494\n",
      "Epoch 11/20\n",
      "7289/7289 [==============================] - 0s 54us/step - loss: 0.1923 - binary_accuracy: 0.9461 - val_loss: 0.1810 - val_binary_accuracy: 0.9494\n",
      "Epoch 12/20\n",
      "7289/7289 [==============================] - 0s 59us/step - loss: 0.1912 - binary_accuracy: 0.9461 - val_loss: 0.1801 - val_binary_accuracy: 0.9494\n",
      "Epoch 13/20\n",
      "7289/7289 [==============================] - 0s 54us/step - loss: 0.1902 - binary_accuracy: 0.9461 - val_loss: 0.1784 - val_binary_accuracy: 0.9494\n",
      "Epoch 14/20\n",
      "7289/7289 [==============================] - 0s 62us/step - loss: 0.1887 - binary_accuracy: 0.9461 - val_loss: 0.1775 - val_binary_accuracy: 0.9494\n",
      "Epoch 15/20\n",
      "7289/7289 [==============================] - 0s 68us/step - loss: 0.1874 - binary_accuracy: 0.9461 - val_loss: 0.1762 - val_binary_accuracy: 0.9494\n",
      "Epoch 16/20\n",
      "7289/7289 [==============================] - 0s 68us/step - loss: 0.1858 - binary_accuracy: 0.9461 - val_loss: 0.1754 - val_binary_accuracy: 0.9494\n",
      "Epoch 17/20\n",
      "7289/7289 [==============================] - 0s 62us/step - loss: 0.1846 - binary_accuracy: 0.9461 - val_loss: 0.1741 - val_binary_accuracy: 0.9494\n",
      "Epoch 18/20\n",
      "7289/7289 [==============================] - 0s 58us/step - loss: 0.1841 - binary_accuracy: 0.9461 - val_loss: 0.1729 - val_binary_accuracy: 0.9494\n",
      "Epoch 19/20\n",
      "7289/7289 [==============================] - 0s 57us/step - loss: 0.1826 - binary_accuracy: 0.9461 - val_loss: 0.1725 - val_binary_accuracy: 0.9494\n",
      "Epoch 20/20\n",
      "7289/7289 [==============================] - 0s 55us/step - loss: 0.1822 - binary_accuracy: 0.9461 - val_loss: 0.1715 - val_binary_accuracy: 0.9494\n"
     ]
    }
   ],
   "source": [
    "#Run Keras model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "               epochs=20, batch_size=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add some visualization here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "#SCORE MODEL\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model against the kaggle test dataset\n",
    "test_preds = model.predict_proba(Xts)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for keras only\n",
    "#test_preds = test_preds[:,0]\n",
    "test_preds = model.predict_proba(Xts)\n",
    "test_preds = test_preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.roc_auc_score(yts,test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116293, 2)\n"
     ]
    }
   ],
   "source": [
    "#generate output file \n",
    "test_preds = model.predict_proba(Xts)[:,1]\n",
    "output_file = pd.DataFrame({'Id':tsw.Id, 'WnvPresent':test_preds})  \n",
    "#output_file.head()\n",
    "csv_name = 'test_csv.csv'\n",
    "output_file.to_csv(csv_name, index=False)\n",
    "print(output_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file.WnvPres.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
