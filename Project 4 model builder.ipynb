{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "weather = pd.read_csv('weather.csv')\n",
    "spray = pd.read_csv('spray.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge data (only using station 1 so as not to double the data)\n",
    "trw = train.merge(weather[weather['Station']==1], how='left', on='Date')\n",
    "tsw = test.merge(weather[weather['Station']==1], how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Date', 'Address', 'Species', 'Block', 'Street', 'Trap',\n",
       "       'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy',\n",
       "       'Station', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb',\n",
       "       'Heat', 'Cool', 'Sunrise', 'Sunset', 'CodeSum', 'Depth', 'Water1',\n",
       "       'SnowFall', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed',\n",
       "       'ResultDir', 'AvgSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create y\n",
    "ytr = trw.WnvPresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create X\n",
    "Xtr = pd.DataFrame()\n",
    "Xts = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#FEATURE ENGINEERING\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean data, eliminate nulls\n",
    "#create dummies \n",
    "#engineer data data (day of year?, sunrise?)\n",
    "#engineer geographic variables\n",
    "#engineer weather variables (lagging data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build X \n",
    "Xtr['Latitude'] = trw.Latitude\n",
    "Xts['Latitude'] = tsw.Latitude\n",
    "#\n",
    "Xtr['Longitude'] = trw.Longitude\n",
    "Xts['Longitude'] = tsw.Longitude\n",
    "#\n",
    "Xtr['Tmax'] = trw.Tmax.astype(float)\n",
    "Xts['Tmax'] = tsw.Tmax.astype(float)\n",
    "#\n",
    "#Xtr['PrecipTotal']= trw.PrecipTotal.apply(lambda x: 0.1 if x == 'T' else x)\n",
    "#Xts['PrecipTotal']= tsw.PrecipTotal.apply(lambda x: 0.1 if x == 'T' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check dtypes\n",
    "#Xtr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check for nulls\n",
    "#Xtr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Xts.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "#BUILD MODELS\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93270799, 0.93431253, 0.93023256])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######RANDOM FOREST model\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtr, ytr, test_size=0.30, random_state=12)\n",
    "#run random forest with kfold (may not be necessary, but will give an estimate of variance)\n",
    "model = RandomForestClassifier(max_features = 3, max_depth = 1000) \n",
    "scores = cross_val_score(model, X_train, y_train, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502189225204645"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit against full training set\n",
    "model.fit(Xtr,ytr)\n",
    "model.score(Xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#KERAS MODEL\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create keras Model\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtr, ytr, test_size=0.30, random_state=11)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)  #the scaler is fit only to the training data\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_units = X_train.shape[1] #number of features in training set\n",
    "hidden_units = input_units   #hidden layer has the same number of nodes as input\n",
    "\n",
    "#first input layer\n",
    "model.add(Dense(hidden_units            \n",
    "                ,input_dim=input_units  \n",
    "                ,activation='relu'\n",
    "                #uncomment this to add L2 regularization\n",
    "                #,kernel_regularizer=regularizers.l2(0.0001) \n",
    "               ))\n",
    "\n",
    "\n",
    "#hidden layer (try with and without)\n",
    "#node_reduction = 0\n",
    "#model.add(Dense(hidden_units - node_reduction          \n",
    "#                ,input_dim=input_units  \n",
    "#                ,activation='relu'\n",
    "#                #,kernel_regularizer=regularizers.l2(0.0001) \n",
    "#               ))\n",
    "#model.add(Dropout(0.8))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy'\n",
    "              ,optimizer='adam'\n",
    "               #added later (not part of original solution\n",
    "              ,metrics=['binary_accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14708 samples, validate on 6304 samples\n",
      "Epoch 1/10\n",
      "14708/14708 [==============================] - 1s 46us/step - loss: 0.2037 - binary_accuracy: 0.9469 - val_loss: 0.1957 - val_binary_accuracy: 0.9491\n",
      "Epoch 2/10\n",
      "14708/14708 [==============================] - 1s 47us/step - loss: 0.2035 - binary_accuracy: 0.9469 - val_loss: 0.1959 - val_binary_accuracy: 0.9491\n",
      "Epoch 3/10\n",
      "14708/14708 [==============================] - 1s 51us/step - loss: 0.2034 - binary_accuracy: 0.9469 - val_loss: 0.1957 - val_binary_accuracy: 0.9491\n",
      "Epoch 4/10\n",
      "14708/14708 [==============================] - 1s 47us/step - loss: 0.2036 - binary_accuracy: 0.9469 - val_loss: 0.1957 - val_binary_accuracy: 0.9491\n",
      "Epoch 5/10\n",
      "14708/14708 [==============================] - 1s 47us/step - loss: 0.2036 - binary_accuracy: 0.9469 - val_loss: 0.1956 - val_binary_accuracy: 0.9491\n",
      "Epoch 6/10\n",
      "14708/14708 [==============================] - 1s 47us/step - loss: 0.2036 - binary_accuracy: 0.9469 - val_loss: 0.1960 - val_binary_accuracy: 0.9491\n",
      "Epoch 7/10\n",
      "14708/14708 [==============================] - 1s 46us/step - loss: 0.2036 - binary_accuracy: 0.9469 - val_loss: 0.1956 - val_binary_accuracy: 0.9491\n",
      "Epoch 8/10\n",
      "14708/14708 [==============================] - 1s 46us/step - loss: 0.2036 - binary_accuracy: 0.9469 - val_loss: 0.1958 - val_binary_accuracy: 0.9491\n",
      "Epoch 9/10\n",
      "14708/14708 [==============================] - 1s 47us/step - loss: 0.2035 - binary_accuracy: 0.9469 - val_loss: 0.1957 - val_binary_accuracy: 0.9491\n",
      "Epoch 10/10\n",
      "14708/14708 [==============================] - 1s 53us/step - loss: 0.2035 - binary_accuracy: 0.9469 - val_loss: 0.1957 - val_binary_accuracy: 0.9491\n"
     ]
    }
   ],
   "source": [
    "#Run Keras model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "              epochs=10, batch_size=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add some visualization here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "#SCORE MODEL\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5656974534224336"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate AUC-ROC\n",
    "y_preds = model.predict(Xtr)\n",
    "metrics.roc_auc_score(ytr,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run model against test\n",
    "test_preds = model.predict(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsw.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate output file\n",
    "\n",
    "output_file = pd.DataFrame({'Id':tsw.Id, 'WnvPresent':test_preds})\n",
    "#output_file.head()\n",
    "csv_name = 'test_csv.csv'\n",
    "output_file.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
